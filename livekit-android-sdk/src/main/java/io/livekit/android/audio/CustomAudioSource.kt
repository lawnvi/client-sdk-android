/*
 * Copyright 2024 LiveKit, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package io.livekit.android.audio

import android.media.AudioFormat
import io.livekit.android.util.LKLog
import kotlinx.coroutines.*
import livekit.org.webrtc.AudioSource
import livekit.org.webrtc.MediaConstraints
import java.nio.ByteBuffer
import java.util.concurrent.atomic.AtomicBoolean

/**
 * è‡ªå®šä¹‰éŸ³é¢‘æº - å®Œå…¨ç‹¬ç«‹äºéº¦å…‹é£çš„éŸ³é¢‘æ•°æ®æº
 *
 * è¿™ä¸ªç±»å®ç°äº†WebRTC AudioSourceæ¥å£ï¼Œä½†å®Œå…¨ä¸ä¾èµ–éº¦å…‹é£è¾“å…¥ã€‚
 * å®ƒé€šè¿‡è‡ªå®šä¹‰çš„éŸ³é¢‘æ•°æ®æä¾›å™¨æ¥ç”ŸæˆéŸ³é¢‘æ•°æ®ã€‚
 */
class CustomAudioSource(
    private val customAudioProvider: CustomAudioBufferProvider,
    private val audioFormat: Int = AudioFormat.ENCODING_PCM_16BIT,
    private val channelCount: Int = 2,
    private val sampleRate: Int = 44100
) : AudioSource(100L) {

    companion object {
        private const val TAG = "CustomAudioSource"

        // éŸ³é¢‘å¸§é…ç½® (10ms)
        private const val FRAME_DURATION_MS = 10
        private fun getFrameSize(sampleRate: Int, channels: Int, format: Int): Int {
            val bytesPerSample = when (format) {
                AudioFormat.ENCODING_PCM_8BIT -> 1
                AudioFormat.ENCODING_PCM_16BIT -> 2
                AudioFormat.ENCODING_PCM_FLOAT -> 4
                else -> 2
            }
            return sampleRate * channels * bytesPerSample * FRAME_DURATION_MS / 1000
        }
    }

    private val isRunning = AtomicBoolean(false)
    private val audioGeneratorScope = CoroutineScope(Dispatchers.IO + SupervisorJob())
    private var audioGeneratorJob: Job? = null

    // éŸ³é¢‘å¸§é…ç½®
    private val frameSize = getFrameSize(sampleRate, channelCount, audioFormat)

    fun setVolume(volume: Double) {
        LKLog.d { "$TAG: setVolume($volume)" }
        // å¯ä»¥åœ¨è¿™é‡Œå®ç°éŸ³é‡æ§åˆ¶
    }

    /**
     * å¼€å§‹éŸ³é¢‘æ•°æ®ç”Ÿæˆ
     */
    fun startAudioGeneration() {
        if (isRunning.compareAndSet(false, true)) {
            LKLog.d { "$TAG: ğŸµ å¼€å§‹è‡ªå®šä¹‰éŸ³é¢‘ç”Ÿæˆ - æ ¼å¼:$audioFormat å£°é“:$channelCount é‡‡æ ·ç‡:$sampleRate å¸§å¤§å°:$frameSize" }

            customAudioProvider.start()

            audioGeneratorJob = audioGeneratorScope.launch {
                generateAudioFrames()
            }
        }
    }

    /**
     * åœæ­¢éŸ³é¢‘æ•°æ®ç”Ÿæˆ
     */
    fun stopAudioGeneration() {
        if (isRunning.compareAndSet(true, false)) {
            LKLog.d { "$TAG: â¹ï¸ åœæ­¢è‡ªå®šä¹‰éŸ³é¢‘ç”Ÿæˆ" }

            audioGeneratorJob?.cancel()
            audioGeneratorJob = null
            customAudioProvider.stop()
        }
    }

    /**
     * éŸ³é¢‘å¸§ç”Ÿæˆå¾ªç¯
     */
    private suspend fun generateAudioFrames() {
        var frameCount = 0

        while (isRunning.get()) {
            try {
                // ä»æä¾›å™¨è·å–éŸ³é¢‘æ•°æ®
                val audioData = customAudioProvider.provideAudioData(
                    requestedBytes = frameSize,
                    audioFormat = audioFormat,
                    channelCount = channelCount,
                    sampleRate = sampleRate
                )

                if (audioData != null && audioData.hasRemaining()) {
                    // å°†éŸ³é¢‘æ•°æ®å‘é€åˆ°WebRTC
                    sendAudioFrame(audioData)
                    frameCount++

                    if (frameCount % 100 == 0) {
                        LKLog.d { "$TAG: ğŸ“¤ å·²å‘é€ $frameCount ä¸ªéŸ³é¢‘å¸§" }
                    }
                } else {
                    // æ²¡æœ‰éŸ³é¢‘æ•°æ®ï¼Œå‘é€é™éŸ³
                    sendSilenceFrame()
                }

                // æŒ‰ç…§å¸§ç‡å»¶è¿Ÿ
                delay(FRAME_DURATION_MS.toLong())

            } catch (e: Exception) {
                LKLog.e(e) { "$TAG: éŸ³é¢‘å¸§ç”Ÿæˆé”™è¯¯" }
                break
            }
        }

        LKLog.d { "$TAG: éŸ³é¢‘å¸§ç”Ÿæˆå¾ªç¯ç»“æŸï¼Œæ€»å…±å‘é€ $frameCount å¸§" }
    }

    /**
     * å‘é€éŸ³é¢‘å¸§åˆ°WebRTC
     */
    private fun sendAudioFrame(audioData: ByteBuffer) {
        try {
            // å‡†å¤‡éŸ³é¢‘æ•°æ®
            val audioArray = ByteArray(audioData.remaining())
            audioData.get(audioArray)

            // è®¡ç®—æ—¶é—´æˆ³
            val captureTimeMs = System.currentTimeMillis()

            // å‘é€åˆ°WebRTCéŸ³é¢‘å¤„ç†é“¾
            // æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ç›´æ¥è°ƒç”¨WebRTCçš„éŸ³é¢‘å¤„ç†æ–¹æ³•
            // ç”±äºWebRTCçš„Java APIé™åˆ¶ï¼Œæˆ‘ä»¬éœ€è¦é€šè¿‡åå°„æˆ–JNIè°ƒç”¨
            sendAudioDataToWebRTC(audioArray, captureTimeMs)

        } catch (e: Exception) {
            LKLog.e(e) { "$TAG: å‘é€éŸ³é¢‘å¸§å¤±è´¥" }
        }
    }

    /**
     * å‘é€é™éŸ³å¸§
     */
    private fun sendSilenceFrame() {
        val silenceData = ByteArray(frameSize) // å…¨é›¶æ•°ç»„ä»£è¡¨é™éŸ³
        sendAudioDataToWebRTC(silenceData, System.currentTimeMillis())
    }

    /**
     * å°†éŸ³é¢‘æ•°æ®å‘é€åˆ°WebRTCå¤„ç†é“¾
     *
     * æ³¨æ„ï¼šç”±äºWebRTC Java APIçš„é™åˆ¶ï¼Œè¿™é‡Œä½¿ç”¨äº†ä¸€ä¸ªå˜é€šæ–¹æ³•
     * å®é™…å®ç°ä¸­å¯èƒ½éœ€è¦é€šè¿‡JNIæˆ–å…¶ä»–æ–¹å¼æ¥å®ç°
     */
    private fun sendAudioDataToWebRTC(audioData: ByteArray, captureTimeMs: Long) {
        // TODO: è¿™é‡Œéœ€è¦å®ç°å°†éŸ³é¢‘æ•°æ®å‘é€åˆ°WebRTCçš„æœºåˆ¶
        // ç”±äºWebRTC AudioSourceçš„Java APIé™åˆ¶ï¼Œå¯èƒ½éœ€è¦ï¼š
        // 1. ä½¿ç”¨JNIè°ƒç”¨nativeæ–¹æ³•
        // 2. æˆ–è€…é€šè¿‡ä¿®æ”¹WebRTCæºç 
        // 3. æˆ–è€…ä½¿ç”¨å…¶ä»–å˜é€šæ–¹æ³•

        LKLog.v { "$TAG: å‘é€éŸ³é¢‘æ•°æ®: ${audioData.size} å­—èŠ‚, æ—¶é—´æˆ³: $captureTimeMs" }
    }

    override fun dispose() {
        stopAudioGeneration()
        super.dispose()
    }
}

/**
 * è‡ªå®šä¹‰éŸ³é¢‘æºå·¥å‚
 */
class CustomAudioSourceFactory {
    companion object {
        /**
         * åˆ›å»ºè‡ªå®šä¹‰éŸ³é¢‘æº
         */
        fun createCustomAudioSource(
            customAudioProvider: CustomAudioBufferProvider,
            audioFormat: Int = AudioFormat.ENCODING_PCM_16BIT,
            channelCount: Int = 2,
            sampleRate: Int = 44100
        ): CustomAudioSource {
            return CustomAudioSource(
                customAudioProvider = customAudioProvider,
                audioFormat = audioFormat,
                channelCount = channelCount,
                sampleRate = sampleRate
            )
        }
    }
}
